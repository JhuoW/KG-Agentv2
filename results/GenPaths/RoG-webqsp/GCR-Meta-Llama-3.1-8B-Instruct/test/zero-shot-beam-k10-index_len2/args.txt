{
  "data_path": "rmanluo",
  "d": "RoG-webqsp",
  "split": "test",
  "index_path_length": 2,
  "predict_path": "results/GenPaths",
  "model_name": "GCR-Meta-Llama-3.1-8B-Instruct",
  "force": false,
  "gpu_id": "0,1,2",
  "undirected": false,
  "debug": false,
  "prompt_mode": "zero-shot",
  "filter_empty": false,
  "add_rule": false,
  "rule_path": "results/gen_rule_path/webqsp_undirected/Llama-2-7b-chat-hf_align-spectoken-joint/test/predictions_3_False.jsonl",
  "prefix": "",
  "worker_mode": false,
  "worker_gpu": 0,
  "worker_start_idx": 0,
  "worker_end_idx": 0,
  "worker_output_file": "",
  "model_path": "rmanluo/GCR-Meta-Llama-3.1-8B-Instruct",
  "maximum_token": 4096,
  "max_new_tokens": 1024,
  "dtype": "bf16",
  "quant": "none",
  "attn_implementation": "sdpa",
  "generation_mode": "beam",
  "k": 10,
  "chat_model": true,
  "use_assistant_model": false,
  "assistant_model_path": null
}